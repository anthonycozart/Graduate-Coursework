{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 618 WN 2018 - Lab 5: Spark DataFrames\n",
    "\n",
    "## Submission Instructions:\n",
    "Please turn in this Jupyter notebook file (both .ipynb and .html formats) on Canvas before midnight.\n",
    "\n",
    "### Name:  Anthony Cozart\n",
    "### Uniqname: Jacozart\n",
    "### People you worked with: Anna Lenhart, Lauren Sheridan\n",
    "\n",
    "## Objectives:\n",
    "* Know the basics of PySpark SQL manipulation\n",
    "* Initialize a Spark Session\n",
    "* Create a Spark DataFrame from a CSV file\n",
    "* Select subset of data using .filter()\n",
    "* Sort DataFrame on one ore more columns using .sortBy()\n",
    "* Group data and calculate aggregate statistics using .groupBy() and .agg()\n",
    "* Run SQL queries in Spark\n",
    "* Know how to transform between Spark DataFrame and Pandas DataFrame\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "## Note: If you get stuck, ask for help or try to move onto the next question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Chocolate Bar Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "This dataset is compiled by Brady Brelinski, Founding Member of the Manhattan Chocolate Society. It provides expert ratings for over 1,700 individual chocolate bars, along with information on their regional origin, percentage of cocoa, the variety of chocolate bean used and where the beans were grown. The dataset was obtained from Kaggle: https://www.kaggle.com/rtatman/chocolate-bar-ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "Here's a description of the fields available in this dataset.\n",
    "\n",
    "| Field | Description |\n",
    "| --- | --- |\n",
    "| Company (Maker-if known) | Name of the company manufacturing the bar.| \n",
    "| Specific Bean Origin or Bar Name | The specific geo-region of origin for the bar.|\n",
    "| REF | |\n",
    "| Review Date | Date of publication of the review.|\n",
    "| Cocoa Percent | Cocoa percentage (darkness) of the chocolate bar being reviewed.|\n",
    "| Company Location | Manufacturer base country. |\n",
    "| Rating | Expert rating for the bar.|\n",
    "| Bean Type | The variety (breed) of bean used, if provided.|\n",
    "| Broad Bean Origin | The broad geo-region of origin for the bean.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's import the SparkSession class from pyspark.sql library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, let's initialize a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('lab5').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's load the chocolate bar data.  You'll be using ```spark.read.csv(...)``` a lot.\n",
    "\n",
    "Set inferSchema=True to infer the variable types; set header=True if the first line of the csv file is the header; set sep='\\t' for tab-separated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"flavors_of_cacao2.txt\", inferSchema=True, header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the schema of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company (Maker-if known): string (nullable = true)\n",
      " |-- Specific Bean Origin or Bar Name: string (nullable = true)\n",
      " |-- REF: integer (nullable = true)\n",
      " |-- Review Date: integer (nullable = true)\n",
      " |-- Cocoa Percent: string (nullable = true)\n",
      " |-- Company Location: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- Bean Type: string (nullable = true)\n",
      " |-- Broad Bean Origin: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As part of loading data, it's helpful to get an idea of the shape of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows of the dataset is:  1795\n",
      "The number of columns of the dataset is:  9\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of rows of the dataset is: \", df.count())\n",
    "print(\"The number of columns of the dataset is: \", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update and Remove Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how to drop a column, let's create a small DataFrame from a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "| name|course|score|\n",
      "+-----+------+-----+\n",
      "|Chris| SI618|   98|\n",
      "|  Kai| SI699|   85|\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df = spark.createDataFrame(\n",
    "    [('Chris','SI618',98), ('Kai','SI699',85)],['name','course','score']\n",
    ")\n",
    "temp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name|course|\n",
      "+-----+------+\n",
      "|Chris| SI618|\n",
      "|  Kai| SI699|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.drop(\"score\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q1: Drop the column \"REF\" and save it back to df. We will not use this unknown variable for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------------------+----+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|Company (Maker-if known)|Specific Bean Origin or Bar Name| REF|Review Date|Cocoa Percent|Company Location|Rating|Bean Type|Broad Bean Origin|\n",
      "+------------------------+--------------------------------+----+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|                A. Morin|                     Agua Grande|1876|       2016|          63%|          France|  3.75|         |         Sao Tome|\n",
      "|                A. Morin|                           Kpime|1676|       2015|          70%|          France|  2.75|         |             Togo|\n",
      "|                A. Morin|                          Atsane|1676|       2015|          70%|          France|   3.0|         |             Togo|\n",
      "|                A. Morin|                           Akata|1680|       2015|          70%|          France|   3.5|         |             Togo|\n",
      "|                A. Morin|                          Quilla|1704|       2015|          70%|          France|   3.5|         |             Peru|\n",
      "|                A. Morin|                        Carenero|1315|       2014|          70%|          France|  2.75|  Criollo|        Venezuela|\n",
      "|                A. Morin|                            Cuba|1315|       2014|          70%|          France|   3.5|         |             Cuba|\n",
      "|                A. Morin|                    Sur del Lago|1315|       2014|          70%|          France|   3.5|  Criollo|        Venezuela|\n",
      "|                A. Morin|                  Puerto Cabello|1319|       2014|          70%|          France|  3.75|  Criollo|        Venezuela|\n",
      "|                A. Morin|                         Pablino|1319|       2014|          70%|          France|   4.0|         |             Peru|\n",
      "+------------------------+--------------------------------+----+-----------+-------------+----------------+------+---------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"REF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some column names are too long and can be shortened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('Company\\xa0(Maker-if known)', 'Company Name')\n",
    "df = df.withColumnRenamed('Specific Bean Origin or Bar Name', 'Specific Bean Origin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some columns have a blank space in their names, so renaming them can save us trouble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q2: Replace the blank space of column names with underscore.\n",
    "Hint1: instead of renaming the columns one by one, you can use a for loop.\n",
    "\n",
    "Hint2: for each column name, do a split and join the resulting list with an underscore. For example, \",\".join([\"How are you\",\"Ma'am\"]) gives you a string \"How are you,Ma'am\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df.schema.names:\n",
    "    words = col.split(\" \")\n",
    "    renamed = '_'.join(words)\n",
    "    df = df.withColumnRenamed(col, renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|Company_Name|Specific_Bean_Origin|Review_Date|Cocoa_Percent|Company_Location|Rating|Bean_Type|Broad_Bean_Origin|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|    A. Morin|         Agua Grande|       2016|          63%|          France|  3.75|         |         Sao Tome|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company_Name: string (nullable = true)\n",
      " |-- Specific_Bean_Origin: string (nullable = true)\n",
      " |-- Review_Date: integer (nullable = true)\n",
      " |-- Cocoa_Percent: string (nullable = true)\n",
      " |-- Company_Location: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- Bean_Type: string (nullable = true)\n",
      " |-- Broad_Bean_Origin: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "df.printSchema() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code convert Cocoa Percent from string type to float type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "df = df.withColumn(\"Cocoa_Percent\", regexp_extract('Cocoa_Percent', r'^[0-9]+', 0).cast('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing the first row is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|Company_Name|Specific_Bean_Origin|Review_Date|Cocoa_Percent|Company_Location|Rating|Bean_Type|Broad_Bean_Origin|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|    A. Morin|         Agua Grande|       2016|         63.0|          France|  3.75|         |         Sao Tome|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use .take(), which returns a list of Row objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Company_Name='A. Morin', Specific_Bean_Origin='Agua Grande', Review_Date=2016, Cocoa_Percent=63.0, Company_Location='France', Rating=3.75, Bean_Type='\\xa0', Broad_Bean_Origin='Sao Tome')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can sample a subset of data using .sample()\n",
    "For example, you can sample 10% of the data points without replacement like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Company_Name='A. Morin', Specific_Bean_Origin='Madagascar', Review_Date=2013, Cocoa_Percent=70.0, Company_Location='France', Rating=3.0, Bean_Type='Criollo', Broad_Bean_Origin='Madagascar')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(False, 0.1).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q3: Extract the Company Name and Company Location of the first row.\n",
    "\n",
    "Hint: use.take(), extract the first element of the list, and select the fields using (\"A\", \"B\", \"C\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Company_Name='A. Morin', Company_Location='France')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('Company_Name','Company_Location').take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Pandas, Spark's function input can be simply separated by commas, instead of a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to select a field or multiple fields, simply field names by commas in the function, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+------+\n",
      "|Company_Name|Specific_Bean_Origin|Rating|\n",
      "+------------+--------------------+------+\n",
      "|    A. Morin|         Agua Grande|  3.75|\n",
      "+------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Company_Name\" ,\"Specific_Bean_Origin\", \"Rating\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can select in a bracket format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+------+\n",
      "|Company_Name|Specific_Bean_Origin|Rating|\n",
      "+------------+--------------------+------+\n",
      "|    A. Morin|         Agua Grande|  3.75|\n",
      "+------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"Company_Name\"], df[\"Specific_Bean_Origin\"], df[\"Rating\"]).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the field name doesn't contain a space, then you can also use a dot format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+------+\n",
      "|Company_Name|Specific_Bean_Origin|Rating|\n",
      "+------------+--------------------+------+\n",
      "|    A. Morin|         Agua Grande|  3.75|\n",
      "+------------+--------------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.Company_Name, df.Specific_Bean_Origin, df.Rating).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q4: Take a random sample of 5 records and show only their company names and company locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|        Company_Name|Specific_Bean_Origin|\n",
      "+--------------------+--------------------+\n",
      "| Artisan du Chocolat|          Costa Rica|\n",
      "|           Dandelion|Zorzal Reserva, 2...|\n",
      "|            Ambrosia|                Peru|\n",
      "|         Bahen & Co.|          Houseblend|\n",
      "|Heirloom Cacao Pr...|Maunawili, O'ahu,...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.sample(False, 1/(df.count()/5)).\n",
    "take5 = spark.createDataFrame(df.rdd.takeSample(False,5))\n",
    "take5.select(take5['Company_Name'], take5['Specific_Bean_Origin']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Columns with WHEN manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark's WHEN corresponds to SQL's CASE WHEN clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If chocolate bars with smaller than 35% cocoa are considered sweet and otherwise bitter, then we can show this as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-------------+------+-----------+\n",
      "|Company_Name|Specific_Bean_Origin|SweetOrBitter|Rating|Review_Date|\n",
      "+------------+--------------------+-------------+------+-----------+\n",
      "|    A. Morin|         Agua Grande|       Bitter|  3.75|       2016|\n",
      "|    A. Morin|               Kpime|       Bitter|  2.75|       2015|\n",
      "|    A. Morin|              Atsane|       Bitter|   3.0|       2015|\n",
      "|    A. Morin|               Akata|       Bitter|   3.5|       2015|\n",
      "|    A. Morin|              Quilla|       Bitter|   3.5|       2015|\n",
      "+------------+--------------------+-------------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.select(\"Company_Name\", \n",
    "          \"Specific_Bean_Origin\",\n",
    "          F.when(df.Cocoa_Percent<35, \"Sweet\").otherwise(\"Bitter\").alias(\"SweetOrBitter\"), \n",
    "          \"Rating\", \"Review_Date\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q5: Show Company_Name, Specific_Bean_Origin, Review_Date, and Descriptive Rating according to the following conditions:\n",
    "\n",
    "\\>=5: Elite (Transcending beyond the ordinary limits)\n",
    "\n",
    "\\>=4: Premium (Superior flavor development, character and style)\n",
    "\n",
    "\\>=3: Satisfactory (well made with special qualities)\n",
    "\n",
    "\\>=2: Disappointing (Passable but contains at least one significant flaw)\n",
    "\n",
    "<2: Unpleasant (mostly unpalatable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+------------------+\n",
      "|Company_Name|Specific_Bean_Origin|Review_Date|Descriptive_Rating|\n",
      "+------------+--------------------+-----------+------------------+\n",
      "|    A. Morin|         Agua Grande|       2016|      Satisfactory|\n",
      "|    A. Morin|               Kpime|       2015|     Disappointing|\n",
      "|    A. Morin|              Atsane|       2015|      Satisfactory|\n",
      "|    A. Morin|               Akata|       2015|      Satisfactory|\n",
      "|    A. Morin|              Quilla|       2015|      Satisfactory|\n",
      "|    A. Morin|            Carenero|       2014|     Disappointing|\n",
      "|    A. Morin|                Cuba|       2014|      Satisfactory|\n",
      "|    A. Morin|        Sur del Lago|       2014|      Satisfactory|\n",
      "|    A. Morin|      Puerto Cabello|       2014|      Satisfactory|\n",
      "|    A. Morin|             Pablino|       2014|           Premium|\n",
      "|    A. Morin|              Panama|       2013|     Disappointing|\n",
      "|    A. Morin|          Madagascar|       2013|      Satisfactory|\n",
      "|    A. Morin|              Brazil|       2013|      Satisfactory|\n",
      "|    A. Morin|            Equateur|       2013|      Satisfactory|\n",
      "|    A. Morin|            Colombie|       2013|     Disappointing|\n",
      "|    A. Morin|            Birmanie|       2013|      Satisfactory|\n",
      "|    A. Morin|    Papua New Guinea|       2013|      Satisfactory|\n",
      "|    A. Morin|               Chuao|       2013|           Premium|\n",
      "|    A. Morin|               Piura|       2013|      Satisfactory|\n",
      "|    A. Morin|Chanchamayo Province|       2013|      Satisfactory|\n",
      "+------------+--------------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Company_Name\", \n",
    "          \"Specific_Bean_Origin\",\n",
    "          \"Review_Date\",\n",
    "          F.when(df.Rating >= 5, \"Elite\")\n",
    "          .when((df.Rating >= 4) & (df.Rating < 5), \"Premium\")\n",
    "          .when((df.Rating >= 3) & (df.Rating < 4), \"Satisfactory\")\n",
    "          .when((df.Rating >= 2) & (df.Rating < 3), \"Disappointing\")\n",
    "          .otherwise(\"Unpleasant\").alias(\"Descriptive_Rating\")).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Columns with Arithmetic Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply arithmetic operation on a column during column selection, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|(Cocoa_Percent / 100)|\n",
      "+---------------------+\n",
      "|                 0.63|\n",
      "+---------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"Cocoa_Percent\"]/100).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q6: Suppose now we define a cocoa tasty score as the product of cocoa_percentage and rating divided by 100. Compute and show the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|((Cocoa_Percent * Rating) / 100)|\n",
      "+--------------------------------+\n",
      "|                          2.3625|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select((df.Cocoa_Percent*df.Rating)/100).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing statistics of a variable is similar to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            Rating|\n",
      "+-------+------------------+\n",
      "|  count|              1795|\n",
      "|   mean| 3.185933147632312|\n",
      "| stddev|0.4780623935863306|\n",
      "|    min|               1.0|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Rating\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember boolean masking in Pandas? We can do the same thing in PySpark. For example, if we want to see only the ratings reviewed in 2014:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|Company_Name|Specific_Bean_Origin|Review_Date|Cocoa_Percent|Company_Location|Rating|Bean_Type|Broad_Bean_Origin|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|    A. Morin|            Carenero|       2014|         70.0|          France|  2.75|  Criollo|        Venezuela|\n",
      "|    A. Morin|                Cuba|       2014|         70.0|          France|   3.5|         |             Cuba|\n",
      "|    A. Morin|        Sur del Lago|       2014|         70.0|          France|   3.5|  Criollo|        Venezuela|\n",
      "|    A. Morin|      Puerto Cabello|       2014|         70.0|          France|  3.75|  Criollo|        Venezuela|\n",
      "|    A. Morin|             Pablino|       2014|         70.0|          France|   4.0|         |             Peru|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Review_Date\"]==2014).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q7: Find the records of chocolate bars with ratings being at least 3 (including 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|Company_Name|Specific_Bean_Origin|Review_Date|Cocoa_Percent|Company_Location|Rating|Bean_Type|Broad_Bean_Origin|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|    A. Morin|         Agua Grande|       2016|         63.0|          France|  3.75|         |         Sao Tome|\n",
      "|    A. Morin|              Atsane|       2015|         70.0|          France|   3.0|         |             Togo|\n",
      "|    A. Morin|               Akata|       2015|         70.0|          France|   3.5|         |             Togo|\n",
      "|    A. Morin|              Quilla|       2015|         70.0|          France|   3.5|         |             Peru|\n",
      "|    A. Morin|                Cuba|       2014|         70.0|          France|   3.5|         |             Cuba|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Rating\"] >= 3).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, if you want to filter by checking the field against multiple values, use .isin() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------+----------------+------+----------+-----------------+\n",
      "|Company_Name|Specific_Bean_Origin|Review_Date|Cocoa_Percent|Company_Location|Rating| Bean_Type|Broad_Bean_Origin|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+----------+-----------------+\n",
      "|  Chocola'te|          Madagascar|       2011|         70.0|          U.S.A.|  3.75|Trinitario|       Madagascar|\n",
      "|  Chocola'te|           Venezuela|       2011|         68.0|          U.S.A.|  3.75|          |        Venezuela|\n",
      "|       Malmo|               Chuao|       2016|         70.0|          Sweden|   3.0|          |        Venezuela|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Company_Name\"].isin(\"Chocola'te\",\"Malmo\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q8: Show the company names and ratings of chocolate bars produced by a French or Belgian company and reviewed in 2015. \n",
    "\n",
    "Hint: remember boolean masking with multiple conditions in Pandas? Similarly, we can use **&** operator here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|     Company_Name|Rating|\n",
      "+-----------------+------+\n",
      "|         A. Morin|  2.75|\n",
      "|         A. Morin|   3.0|\n",
      "|         A. Morin|   3.5|\n",
      "|         A. Morin|   3.5|\n",
      "|Frederic Blondeel|   3.5|\n",
      "+-----------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Company_Name','Rating').filter(df['Company_Location'].isin('France','Belgium')).filter(df['Review_Date'] == 2015).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "If you want to sort the chocolate bars firstly by cocoa percentage in descending order, and secondly by company in alphabetic order, then you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+-------------+----------------+------+------------------+-------------------+\n",
      "|        Company_Name|Specific_Bean_Origin|Review_Date|Cocoa_Percent|Company_Location|Rating|         Bean_Type|  Broad_Bean_Origin|\n",
      "+--------------------+--------------------+-----------+-------------+----------------+------+------------------+-------------------+\n",
      "| Artisan du Chocolat|           Venezuela|       2010|        100.0|            U.K.|  1.75|                  |          Venezuela|\n",
      "|              Bonnat|         One Hundred|       2006|        100.0|          France|   1.5|                  |                   |\n",
      "|Bouga Cacao (Tuli...|El Oro, Hacienda ...|       2009|        100.0|         Ecuador|   1.5|Forastero (Arriba)|            Ecuador|\n",
      "|             C-Amaro|             Ecuador|       2013|        100.0|           Italy|   3.5|                  |            Ecuador|\n",
      "|     Claudio Corallo|            Principe|       2008|        100.0|        Sao Tome|   1.0|         Forastero|Sao Tome & Principe|\n",
      "+--------------------+--------------------+-----------+-------------+----------------+------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy([\"Cocoa_Percent\", \"Company_Name\"], ascending=[False,True]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q9: Kai wants to buy chocolate bars for Valentine's Day. Provide a sorted list for him to review. His preference is listed below in order:\n",
    "\n",
    "1. Must be reviewed in 2016\n",
    "\n",
    "2. The broad bean origin must be from Brazil, or Peru\n",
    "\n",
    "3. The higher the rating, the better\n",
    "\n",
    "4. The higher the cocoa percent, the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+-------------+\n",
      "|        Company_Name|Specific_Bean_Origin|Rating|Cocoa_Percent|\n",
      "+--------------------+--------------------+------+-------------+\n",
      "|               Batch|              Brazil|  3.75|         70.0|\n",
      "|Manufaktura Czeko...|                Peru|   3.5|         70.0|\n",
      "|                 Cao|              Brazil|  3.25|         70.0|\n",
      "|          Summerbird|                Peru|   3.0|         71.0|\n",
      "|          Two Ravens|                Peru|   3.0|         60.0|\n",
      "|           Heilemann|                Peru|  2.75|         64.0|\n",
      "|               Vivra|                Peru|   2.5|         70.0|\n",
      "|          Summerbird|                Peru|   2.5|         61.0|\n",
      "+--------------------+--------------------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Company_Name','Specific_Bean_Origin','Rating','Cocoa_Percent'])\\\n",
    "    .filter(df.Review_Date==2016).filter(df.Specific_Bean_Origin.isin('Brazil','Peru'))\\\n",
    "    .orderBy(['Rating','Cocoa_Percent'], ascending=[False,False]).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by and Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can summarize statistics in different groups in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|Review_Date|       avg(Rating)|\n",
      "+-----------+------------------+\n",
      "|       2007|3.1623376623376624|\n",
      "|       2015|3.2464912280701754|\n",
      "|       2006|             3.125|\n",
      "|       2013|3.1970108695652173|\n",
      "|       2014|3.1892712550607287|\n",
      "|       2012| 3.178205128205128|\n",
      "|       2009| 3.073170731707317|\n",
      "|       2016|3.2260273972602738|\n",
      "|       2010|3.1486486486486487|\n",
      "|       2011| 3.256060606060606|\n",
      "|       2008|2.9946236559139785|\n",
      "|       2017|            3.3125|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Review_Date\").agg({'Rating': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|Review_Date|max(Rating)|\n",
      "+-----------+-----------+\n",
      "|       2007|        5.0|\n",
      "|       2015|        4.0|\n",
      "|       2006|        5.0|\n",
      "|       2013|        4.0|\n",
      "|       2014|        4.0|\n",
      "|       2012|        4.0|\n",
      "|       2009|        4.0|\n",
      "|       2016|        4.0|\n",
      "|       2010|        4.0|\n",
      "|       2011|        4.0|\n",
      "|       2008|        4.0|\n",
      "|       2017|       3.75|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Review_Date\").agg({'Rating': 'max'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q10: Find the average rating for each company for each review year, of the British chocolate bars, sorted by 1) year from the earliest to latest and 2) averag rating from highest to lowest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+\n",
      "|        Company_Name|Review_Date|       avg(Rating)|\n",
      "+--------------------+-----------+------------------+\n",
      "|Green & Black's (...|       2006|               2.5|\n",
      "| Artisan du Chocolat|       2008|              3.75|\n",
      "|Hotel Chocolat (C...|       2008|            2.8125|\n",
      "|      Willie's Cacao|       2009|             3.125|\n",
      "| Artisan du Chocolat|       2009|2.7083333333333335|\n",
      "|      Willie's Cacao|       2010|3.4166666666666665|\n",
      "|             Duffy's|       2010|             3.375|\n",
      "| Artisan du Chocolat|       2010|               3.1|\n",
      "|Hotel Chocolat (C...|       2010|2.8333333333333335|\n",
      "|             Duffy's|       2011|               3.4|\n",
      "| Artisan du Chocolat|       2011|             3.375|\n",
      "|Hotel Chocolat (C...|       2011|3.0833333333333335|\n",
      "|             Duffy's|       2012|              3.75|\n",
      "| Artisan du Chocolat|       2012|              3.75|\n",
      "|Rococo (Grenada C...|       2012|               3.5|\n",
      "|Hotel Chocolat (C...|       2012|               3.5|\n",
      "| Artisan du Chocolat|       2013|              3.25|\n",
      "|Hotel Chocolat (C...|       2013|               3.0|\n",
      "|      Hotel Chocolat|       2013|             2.875|\n",
      "|Artisan du Chocol...|       2013|              2.75|\n",
      "+--------------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uk_bars = df.filter(df['Company_Location'] == \"U.K.\")\\\n",
    "                .groupBy(['Company_Name','Review_Date']).agg({'Rating': 'mean'})\\\n",
    "                .orderBy(['Review_Date','avg(Rating)'], ascending=[True,False]).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SQL Queries in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run SQL queries, we need to first create a temporary view from a Spark DataFrame. We can do this using .createOrReplaceTempView(), which creates a new view or replace an existing view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chocolate_bars = df.createOrReplaceTempView(\"chocolate_bars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our first query to show the temporary view we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|Company_Name|Specific_Bean_Origin|Review_Date|Cocoa_Percent|Company_Location|Rating|Bean_Type|Broad_Bean_Origin|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "|    A. Morin|         Agua Grande|       2016|         63.0|          France|  3.75|         |         Sao Tome|\n",
      "+------------+--------------------+-----------+-------------+----------------+------+---------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM chocolate_bars\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q11: Write a Spark SQL query to find the average rating for each company that satisfies the following conditions:\n",
    "\n",
    "**1. the chocolate bars were reviewed in 2016 **\n",
    "\n",
    "**2. the chocolate bars were made by companies in this list: 'Germany','France','Spain','Sweden','Denmark','Finland'**\n",
    "\n",
    "**3. the company should have at least 2 chocolate bar reviews **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+------------------+\n",
      "|Company_Name|Count|        Avg_Rating|\n",
      "+------------+-----+------------------+\n",
      "|    Belyzium|    3|3.0833333333333335|\n",
      "|  Summerbird|    2|              2.75|\n",
      "+------------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "    Company_Name,\n",
    "    COUNT(Company_Name) AS Count,\n",
    "    AVG(Rating) AS Avg_Rating\n",
    "    FROM chocolate_bars\n",
    "    WHERE Review_Date = 2016\n",
    "    AND Company_Location IN ('Germany', 'France', 'Spain', 'Sweden', 'Denmark', 'Finland')\n",
    "    GROUP BY Company_Name\n",
    "    HAVING Count >= 2\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Spark DataFrame to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert the Spark DataFrame into a Pandas DataFrame using .toPandas()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Q12: \n",
    "### <font color=\"magenta\"> (1) Write a Spark SQL to find the average cocoa percentage for each company in the U.K. and order the result by the average cocoa percentage from highest to lowest. \n",
    "### <font color=\"magenta\"> (2) Convert the query result into a Pandas DataFrame, save it into a variable \"query_result\" , and show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "    Company_Name,\n",
    "    AVG(Cocoa_Percent) AS Avg_Cocoa_Percent\n",
    "    FROM chocolate_bars\n",
    "    WHERE Company_Location = 'U.K.'\n",
    "    GROUP BY Company_Name\n",
    "    ORDER BY Avg_Cocoa_Percent DESC\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Avg_Cocoa_Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hotel Chocolat</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hotel Chocolat (Coppeneur)</td>\n",
       "      <td>78.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>76.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Solkiki</td>\n",
       "      <td>76.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pump Street Bakery</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dormouse</td>\n",
       "      <td>75.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Doble &amp; Bignall</td>\n",
       "      <td>75.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Artisan du Chocolat</td>\n",
       "      <td>74.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beau Cacao</td>\n",
       "      <td>72.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Artisan du Chocolat (Casa Luker)</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Forever Cacao</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Duffy's</td>\n",
       "      <td>70.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Seaforth</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chocolarder</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Black River (A. Morin)</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chocablog</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Green &amp; Black's (ICAM)</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Damson</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Paul Young</td>\n",
       "      <td>68.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rococo (Grenada Chocolate Co.)</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Company_Name  Avg_Cocoa_Percent\n",
       "0                     Hotel Chocolat          80.000000\n",
       "1         Hotel Chocolat (Coppeneur)          78.105263\n",
       "2                     Willie's Cacao          76.500000\n",
       "3                            Solkiki          76.500000\n",
       "4                 Pump Street Bakery          76.000000\n",
       "5                           Dormouse          75.500000\n",
       "6                    Doble & Bignall          75.250000\n",
       "7                Artisan du Chocolat          74.625000\n",
       "8                         Beau Cacao          72.500000\n",
       "9   Artisan du Chocolat (Casa Luker)          72.000000\n",
       "10                     Forever Cacao          72.000000\n",
       "11                           Duffy's          70.846154\n",
       "12                          Seaforth          70.000000\n",
       "13                       Chocolarder          70.000000\n",
       "14            Black River (A. Morin)          70.000000\n",
       "15                         Chocablog          70.000000\n",
       "16            Green & Black's (ICAM)          70.000000\n",
       "17                            Damson          70.000000\n",
       "18                        Paul Young          68.500000\n",
       "19    Rococo (Grenada Chocolate Co.)          66.000000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result.toPandas() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pandas DataFrame to Spark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert \"query_result\" back to a Spark DataFrame using spark.createDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|        Company_Name|AVG_Cocoa_Percent|\n",
      "+--------------------+-----------------+\n",
      "|      Hotel Chocolat|             80.0|\n",
      "|Hotel Chocolat (C...|78.10526315789474|\n",
      "|      Willie's Cacao|             76.5|\n",
      "|             Solkiki|             76.5|\n",
      "|  Pump Street Bakery|             76.0|\n",
      "|            Dormouse|             75.5|\n",
      "|     Doble & Bignall|            75.25|\n",
      "| Artisan du Chocolat|           74.625|\n",
      "|          Beau Cacao|             72.5|\n",
      "|Artisan du Chocol...|             72.0|\n",
      "|       Forever Cacao|             72.0|\n",
      "|             Duffy's|70.84615384615384|\n",
      "|            Seaforth|             70.0|\n",
      "|         Chocolarder|             70.0|\n",
      "|Black River (A. M...|             70.0|\n",
      "|           Chocablog|             70.0|\n",
      "|Green & Black's (...|             70.0|\n",
      "|              Damson|             70.0|\n",
      "|          Paul Young|             68.5|\n",
      "|Rococo (Grenada C...|             66.0|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(query_result).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Lab 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
