{"cells":[{"cell_type":"markdown","source":["# SI 618 - Homework 7 - Clustering Bob Ross paintings using k-means\n\n## Objectives\n* Practice k-means clustering\n* Gain experience moving between pandas and Spark (both ways)\n\n## Submission Instructions:\nPlease turn in this Databricks notebook in HTML format as well as the URL to the published version of this notebook via Canvas."],"metadata":{}},{"cell_type":"markdown","source":["## Background\n### Bob Ross\nFor this particular exercise we're going to use k-means clustering to analyse Bob Ross paintings.  I was inspired by the FiveThirtyEight article on his work, which you should read for background:\n\nhttps://fivethirtyeight.com/features/a-statistical-analysis-of-the-work-of-bob-ross/\n\nFor those of you unfamiliar with Bob (\"Happy Trees\") Ross... check out his videos on YouTube (e.g. https://www.youtube.com/watch?v=kJFB6rH3z2A) and the Wikipedia page on him.  We're going to use the data provided by fivethirtyeight but will also augment it with the actual images. We've downloaded a few hundred thumbnails and will use those as well.\n\n**NOTE:** Do not attempt to just run this entire notebook.  Read over each step before you run it and try to understand what's going on."],"metadata":{}},{"cell_type":"markdown","source":["### CODE FOR DATA PREPARATION AND THE FIRST K-MEANS ANALYSIS IS DONE FOR YOU!\nYou should study and attempt to understand the code before you move on to \ncompleting parts 2-6 (and, optionally, one of the \"Above and Beyond\" tasks)."],"metadata":{}},{"cell_type":"markdown","source":["### As a first step, let's load the libraries we need:"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport seaborn as sns\nimport matplotlib.cm as cm\nimport re\nimport os.path"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Getting the data from Amazon Web Services S3\n\nWe need the CSV file with data (bob_ross.csv), as well as a collection of images to complete this assignment.\nOne way for us to share those with you is to put them in an AWS S3 bucket and get you to \"mount\" that bucket\nas a directory that's accessible via this notebook.\n\nThe following code block does exactly that, making the bucket containing those files available to this notebook.  To Spark, it will look like the files live in a directory called ```/mnt/si330w18```.  \nTo pandas, which we will use to read the data, the files will live in ```/dbfs/mnt/si330w18```.  Note the use of ```/dbfs``` as a prefix in the pandas version.\n\nYou should be able to just run the next code block.  At the end of the code block is a command to list the contents of the \nmounted S3 bucket."],"metadata":{}},{"cell_type":"code","source":["ACCESS_KEY = \nSECRET_KEY = \nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"umsi-data-science-west\"\nMOUNT_NAME = \"umsi-data-science\"\ntry:\n  dbutils.fs.unmount(\"/mnt/%s/\" % MOUNT_NAME)\nexcept:\n  print(\"Could not unmount %s, but that's ok.\" % MOUNT_NAME)\ndbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\ndisplay(dbutils.fs.ls(\"/mnt/umsi-data-science/si618wn2017\"))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["### Defining a helper function to simplify the color space of images\nThe next code block sets up a utility function (```getColors```), which takes an image and figures out which colors are used.\nIt reduces the color space to about 85 colors (from an original space of 65536 colors) and returns the normalized count of \neach color's appearance in the image.\n\nThe function takes as input the filename of an image file.  It opens the file and sets up a numpy array of zeros for each of the\n85 output colors.  The function then goes through all of the pixels in the image and calculates the red, green and blue \ncolor values in the reduced space (that's why we divide each of the values for red, green and blue by 63).  We then put\nthe red, green and blue values back together again by bit-shifting the green and blue values and then using a logical 'or'.\nLet's say we had a color of 126,189,252 (which is an pleasant blue color).  Dividing those values by 63, we get 2,3,4.\nBit-shifting 3 << 2 gives us 12, 4 << 4 gives us 64.  We don't bit-shift the red values, so we just keep the 2.  Adding those\ntogether (equivalent to using a logical \"or\" on the bit-shifted values) gives us 78, so we would increment the count of color 78.\n\nFinally, we convert all counts to proportions and return the proportions of each color as a numpy array."],"metadata":{}},{"cell_type":"code","source":["def getColors(img):\n    im = Image.open(img, 'r')\n    width, height = im.size\n    #print(img,width,height)\n    pixel_values = list(im.getdata())\n    cnt = np.zeros(85,dtype=int)\n    for i in pixel_values:\n        #print(i)\n        r = int(i[0]/63)\n        g = int(i[1]/63)<<2\n        b = int(i[2]/63)<<4\n        x = r | g | b\n        #print(x)\n        cnt[x] = cnt[x] + 1\n        #print(cnt[x])\n    cnt = cnt/float(sum(cnt))\n    return(cnt)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["### Loading the \"tags' file into a pandas DataFrame\nFirst, we're going to load the CSV file of the human-assigned tags for each of Bob's paintings into a **pandas** DataFrame.  Remember that we mounted the AWS S3 bucket containing the data as ```/mnt/umsi-data-science/si618wn2017``` and the CSV file is named ```bob_ross.csv```.  We can read the file using the (hopefully)\nfamiliar ```.from_csv()``` method in pandas:"],"metadata":{}},{"cell_type":"code","source":["bob_ross = pd.DataFrame.from_csv(\"/dbfs/mnt/umsi-data-science/si618wn2017/bob_ross.csv\")"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Let's take a look at the contents:"],"metadata":{}},{"cell_type":"code","source":["bob_ross.head()\nbob_ross.shape"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["The above command should show you that you have a pandas DataFrame with 5 rows and 68 columns.  These are the \"tags\" for each of the images that\nwe will load.  The tags were generated by people, and indicate the presence or absence of various features (e.g. \"BEACH\"), which is set to 1 if the \nfeature is present or 0 if the feature is not present."],"metadata":{}},{"cell_type":"markdown","source":["## NOTE: The next code block takes a very long time (about 5 minutes) to complete.  Wait for it!"],"metadata":{}},{"cell_type":"code","source":["bob_ross['image'] = \"\"\n# create a column for each of the 85 colors (these will be c0...c84)\n# we'll do this in a separate table for now and then merge\ncols = ['c%s'%i for i in np.arange(0,85)]\ncolors = pd.DataFrame(columns=cols)\ncolors['EPISODE'] = bob_ross.index.values\ncolors = colors.set_index('EPISODE')\n\n# figure out if we have the image or not, we don't have a complete set\nfor s in bob_ross.index.values:\n    b = bob_ross.loc[s]['TITLE']\n    b = b.lower()\n    b = re.sub(r'[^a-z0-9\\s]', '',b)\n    b = re.sub(r'\\s', '_',b)\n    img = b+\".png\"\n    if (os.path.exists(\"/dbfs/mnt/umsi-data-science/si618wn2017/images/\"+img)):\n        bob_ross.set_value(s,\"image\",\"/dbfs/mnt/umsi-data-science/si618wn2017/images/\"+img)\n        t = getColors(\"/dbfs/mnt/umsi-data-science/si618wn2017/images/\"+img)\n        colors.loc[s] = t\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# join the colors and tag database and toss the rows where we don't have an image\nbob_ross = bob_ross.join(colors)\nbob_ross = bob_ross[bob_ross.image != \"\"] "],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# these are masks you might find handy to only get the colors, the tags, or both (as well as the image path)\ncolor_columns = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10',\n               'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17', 'c18', 'c19', 'c20',\n               'c21', 'c22', 'c23', 'c24', 'c25', 'c26', 'c27', 'c28', 'c29', 'c30',\n               'c31', 'c32', 'c33', 'c34', 'c35', 'c36', 'c37', 'c38', 'c39', 'c40',\n               'c41', 'c42', 'c43', 'c44', 'c45', 'c46', 'c47', 'c48', 'c49', 'c50',\n               'c51', 'c52', 'c53', 'c54', 'c55', 'c56', 'c57', 'c58', 'c59', 'c60',\n               'c61', 'c62', 'c63', 'c64', 'c65', 'c66', 'c67', 'c68', 'c69', 'c70',\n               'c71', 'c72', 'c73', 'c74', 'c75', 'c76', 'c77', 'c78', 'c79', 'c80',\n               'c81', 'c82', 'c83', 'c84']\ntag_columns = ['APPLE_FRAME', 'AURORA_BOREALIS', 'BARN', 'BEACH', 'BOAT',\n       'BRIDGE', 'BUILDING', 'BUSHES', 'CABIN', 'CACTUS', 'CIRCLE_FRAME',\n       'CIRRUS', 'CLIFF', 'CLOUDS', 'CONIFER', 'CUMULUS', 'DECIDUOUS',\n       'DIANE_ANDRE', 'DOCK', 'DOUBLE_OVAL_FRAME', 'FARM', 'FENCE', 'FIRE',\n       'FLORIDA_FRAME', 'FLOWERS', 'FOG', 'FRAMED', 'GRASS', 'GUEST',\n       'HALF_CIRCLE_FRAME', 'HALF_OVAL_FRAME', 'HILLS', 'LAKE', 'LAKES',\n       'LIGHTHOUSE', 'MILL', 'MOON', 'MOUNTAIN', 'MOUNTAINS', 'NIGHT', 'OCEAN',\n       'OVAL_FRAME', 'PALM_TREES', 'PATH', 'PERSON', 'PORTRAIT',\n       'RECTANGLE_3D_FRAME', 'RECTANGULAR_FRAME', 'RIVER', 'ROCKS',\n       'SEASHELL_FRAME', 'SNOW', 'SNOWY_MOUNTAIN', 'SPLIT_FRAME', 'STEVE_ROSS',\n       'STRUCTURE', 'SUN', 'TOMB_FRAME', 'TREE', 'TREES', 'TRIPLE_FRAME',\n       'WATERFALL', 'WAVES', 'WINDMILL', 'WINDOW_FRAME', 'WINTER',\n       'WOOD_FRAMED']\nall_columns = color_columns + tag_columns + ['image']\ncolor_columns = color_columns + ['image']\ntag_columns = tag_columns + ['image']"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# this is a utility function for displaying a grid of images, with an optional heading\ndef display_images(imagelist,cluster_title=None):\n    a = imagelist.apply(lambda x: re.search('(\\w+.png)', x).group(1))\n    np.zeros(7-len(a)%7,dtype=np.str)\n    a = np.append(a,np.zeros(7-len(a)%7,dtype=np.str))\n    grid = a.reshape(int(len(a)/7),7)\n    text = \"\"\n    if (cluster_title != None):\n       text = \"<h1>\"+cluster_title+\"</h1>\\n\" \n    text = text + \"<table>\"\n    for i in np.arange(0,len(grid)):\n        row = grid[i]\n        line = ''.join( [\"\\n<TD><img style='width: 120px; margin: 0px; float: left; border: 1px solid black;' src='https://s3.amazonaws.com/si618image/images/%s' /></TD>\" % str(s) for s in row])\n        text = text + \"<TR>\"+line+\"</TR>\\n\"\n    text = text +\"</table>\"\n    displayHTML(text)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# for example, we can display the first 12 images\ndisplay_images(bob_ross.image[0:11],\"sample images\")"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["## K-means\n### 1) K-Means on tags (2 clusters)\n\nWe're going to start by replicating the fivethirtyeight article a bit.  Using *only* the tags, perform a k-means clustering with 2 clusters. Use display_images to show the images from each cluster.\n\n**We are going to move our data into Spark for this analysis.**"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\nfrom pyspark.ml.feature import VectorAssembler\n\ntags = spark.createDataFrame(bob_ross[tag_columns[:-1]])\n\nassembler = VectorAssembler(\n    inputCols=tag_columns[:-1],\n    outputCol=\"features\")\n\ntags_assembled = assembler.transform(tags)\ntags_assembled.select(\"features\").show(5, truncate=False)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# Create k-means model, k=2, and fit the data\nkmeans = KMeans().setK(2).setSeed(1)\nkmeans_model = kmeans.fit(tags_assembled)\n\n# Make predictions\ntags_predictions = kmeans_model.transform(tags_assembled)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Evaluate clustering by computing WSSSE.\nwssse = kmeans_model.computeCost(tags_assembled)\nprint(\"Within Set Sum of Squared Errors = \" + str(wssse))\n\n# Evaluate clustering by computing Silhouette score\nevaluator = ClusteringEvaluator()\nsilhouette = evaluator.evaluate(tags_predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Show the clustering centers\ncenters = kmeans_model.clusterCenters()\nprint(\"Cluster Centers: \")\nfor center in centers:\n    print(center)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# Show the clustering membership\ntags_transformed = kmeans_model.transform(tags_assembled)\ntags_transformed[['prediction']].show(5)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["### Now move back into pandas..."],"metadata":{}},{"cell_type":"code","source":["bob_ross[\"prediction\"] = tags_predictions.select(\"prediction\").toPandas().set_index(bob_ross.index)\n\ndf_0 = bob_ross[bob_ross[\"prediction\"] == 0]\ndisplay_images(df_0['image'],\" Cluster 1 Images\")"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["df_1 = bob_ross[bob_ross[\"prediction\"] == 1]\ndisplay_images(df_1['image'],\"Cluster 2 Images\")"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["### 2) Describe the differences\n\nCluster 1 images have both mountains, typically snow-capped or white, and trees, typically in the foreground. In contrast, Cluster 2 images tend to have trees and cabins, but not mountains. The types of trees are also different; in Cluster 1, the trees are \"evergreen,\" meaning they do not lose their leaves. In Cluster 2, the trees are deciduous -- meaning they lose their leaves. There are many images in cluster two where the trees are leaf-less, or have leaves that are changing colors (i.e., yellow or red or brown)."],"metadata":{}},{"cell_type":"markdown","source":["### 3) Calculate the differences between clusters\n\nOne thing we can do to compare the clusters is to determine which tags show up more in the first cluster and which ones appear more in the second. Write code to determine which tags are maximally different between the two clusters.  You should get output that looks like:\n```\nMOUNTAIN              0.967647\nSNOWY_MOUNTAIN        0.681513\nMOUNTAINS             0.638655\nCONIFER               0.515126\nLAKE                  0.294958\n```\n\nHint: you can do this with some combination of masks, .mean() and .sort_values() all in one line (but feel free to write a loop if it's easier to think about)"],"metadata":{}},{"cell_type":"code","source":["# we have to re-create tag_columns, which includes images in the last column (from cell 19)\ntag_cols = tag_columns[:-1]\n# Now loop through tags\ntag_frequencies = []\nfor column in tag_cols:\n  diff = abs(df_0[column].mean() - df_1[column].mean())\n  tag_frequencies.append(diff)\n\ntable = pd.DataFrame({'Tag':tag_cols, 'Difference':tag_frequencies})\norder = ['Tag','Difference']\ntable = table[order].sort_values('Difference', ascending=False)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["table.head()\n# note a kept getting an error when trying to set Tag as the index, to more closely replicate your example result."],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["### 4) Find a better value of k"],"metadata":{}},{"cell_type":"code","source":["# Method 1: Use your eyeballs!\n# display_images(bob_ross.image,\"All Images\")"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["**Use display_images to show the different clusters, pick the best value of k, and describe your clusters qualitatively.**"],"metadata":{}},{"cell_type":"code","source":["# Method 2: \"Rule of Thumb\"\n# do you round to 14?\nguess = np.sqrt(tags_predictions.count()/2)\nguess"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# method 3: Scree plot\ncost = list()\nfor k in range(2,20):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    kmeans_model = kmeans.fit(tags_assembled)\n    cost.append(kmeans_model.computeCost(tags_assembled))\nprint(cost)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["fig, ax = plt.subplots()\nplt.plot(range(2,20), cost, 'b*-')\nplt.xlabel('Number of clusters');\nplt.ylabel('Within Set Sum of Squared Error');\nplt.title('Elbow for K-Means clustering');\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["The elbow method suggests 6 clusters."],"metadata":{}},{"cell_type":"code","source":["# method 4: Silhouette scores\ncost = list()\nevaluator = ClusteringEvaluator()\nfor k in range(2,20):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    kmeans_model = kmeans.fit(tags_assembled)\n    tags_predictions = kmeans_model.transform(tags_assembled)\n    silhouette = evaluator.evaluate(tags_predictions)\n    cost.append(silhouette)\n    \nkIdx = np.argmax(cost)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,20), cost, 'b*-')\nplt.plot(range(2,20)[kIdx], cost[kIdx], marker='o', markersize=12, \n         markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\nplt.xlim(1, plt.xlim()[1])\nplt.xticks(np.arange(1, 21, 1.0)) # this helps us see the number of clusters we want!\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Coefficient')\nplt.title('Silhouette Scores for k-means clustering')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["The silhouette score suggests we have three clusters. Use this in the code below:"],"metadata":{}},{"cell_type":"code","source":["# Now re-run analysis with k = 3\nkmeans = KMeans().setK(3).setSeed(1)\nkmeans_model = kmeans.fit(tags_assembled)\ntags_predictions = kmeans_model.transform(tags_assembled)\n#tags_transformed = kmeans_model.transform(tags_assembled)\nbob_ross[\"prediction\"] = tags_predictions.select(\"prediction\").toPandas().set_index(bob_ross.index)\n\ndf_0 = bob_ross[bob_ross[\"prediction\"] == 0]\ndisplay_images(df_0['image'],\" Cluster 1 Images\")\n"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["df_1 = bob_ross[bob_ross[\"prediction\"] == 1]\ndisplay_images(df_1['image'],\" Cluster 2 Images\")"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["df_2 = bob_ross[bob_ross[\"prediction\"] == 2]\ndisplay_images(df_2['image'],\" Cluster 3 Images\")"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["When k=3, we can easily see the distinct clusters. \n1. Typically pictures of oceans and/or waves, with pinkish sunsets.\n2. Scenes of trees with no mountains; many have cabins.\n3. Scenes of mountains and trees, typically in dark blue, grey, and green colors."],"metadata":{}},{"cell_type":"markdown","source":["### 5) k-means based on colors\nPerform k-means clustering on the paintings using *only* the color columns. Decide a good value for k, execute the clustering, display the images in each clusters, and describe the resulting clusters."],"metadata":{}},{"cell_type":"code","source":["colors = spark.createDataFrame(bob_ross[color_columns[:-1]])\n\nassembler = VectorAssembler(\n    inputCols=color_columns[:-1],\n    outputCol=\"features\")\n\ncolors_assembled = assembler.transform(colors)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["# Create k-means model, k=2, and fit the data\nkmeans = KMeans().setK(2).setSeed(1)\nkmeans_model = kmeans.fit(colors_assembled)\n\n# Make predictions\ncolors_predictions = kmeans_model.transform(colors_assembled)\n\n# Evaluate clustering by computing WSSSE.\nwssse = kmeans_model.computeCost(colors_assembled)\nprint(\"Within Set Sum of Squared Errors = \" + str(wssse))\n\n# Evaluate clustering by computing Silhouette score\nevaluator = ClusteringEvaluator()\nsilhouette = evaluator.evaluate(colors_predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["What's an appropriate number of clusters?"],"metadata":{}},{"cell_type":"code","source":["# Scree plot\ncost = list()\nfor k in range(2,20):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    kmeans_model = kmeans.fit(colors_assembled)\n    cost.append(kmeans_model.computeCost(colors_assembled))\n\nfig, ax = plt.subplots()\nplt.plot(range(2,20), cost, 'b*-')\nplt.xlabel('Number of clusters');\nplt.ylabel('Within Set Sum of Squared Error');\nplt.title('Elbow for K-Means clustering');\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["The elbow method suggests 8 clusters."],"metadata":{}},{"cell_type":"code","source":["# Check Silhouette scores\ncost = list()\nevaluator = ClusteringEvaluator()\nfor k in range(2,20):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    kmeans_model = kmeans.fit(colors_assembled)\n    colors_predictions = kmeans_model.transform(colors_assembled)\n    silhouette = evaluator.evaluate(colors_predictions)\n    cost.append(silhouette)\n    \nkIdx = np.argmax(cost)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,20), cost, 'b*-')\nplt.plot(range(2,20)[kIdx], cost[kIdx], marker='o', markersize=12, \n         markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\nplt.xlim(1, plt.xlim()[1])\nplt.xticks(np.arange(1, 21, 1.0)) # this helps us see the number of clusters we want!\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Coefficient')\nplt.title('Silhouette Scores for k-means clustering')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":["The Silhouette scores of using just colors suggest two clusters, which I'll do below:"],"metadata":{}},{"cell_type":"code","source":["# Run analysis with k = 2\nkmeans = KMeans().setK(2).setSeed(1)\nkmeans_model = kmeans.fit(colors_assembled)\ncolors_predictions = kmeans_model.transform(colors_assembled)\nbob_ross[\"prediction\"] = tags_predictions.select(\"prediction\").toPandas().set_index(bob_ross.index)\n\ndf_0 = bob_ross[bob_ross[\"prediction\"] == 0]\ndisplay_images(df_0['image'],\" Cluster 1 Images\")"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["df_1 = bob_ross[bob_ross[\"prediction\"] == 1]\ndisplay_images(df_1['image'],\" Cluster 2 Images\")"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":["When k=2, we can easily see the distinct colors.\n1. Lighter colors -- purple, pink, magenta, and yellow.\n2. Darker colors -- green, blue, and brown."],"metadata":{}},{"cell_type":"markdown","source":["### 6) Use both tags and colors for k-means clustering\n\nPerform k-means clustering on the paintings using *both* tag and color columns. Decide a good value for k, execute the clustering, display the images in each clusters, and describe the resulting clusters."],"metadata":{}},{"cell_type":"code","source":["colors_tags = spark.createDataFrame(bob_ross[all_columns[:-1]])\n\nassembler = VectorAssembler(\n    inputCols=all_columns[:-1],\n    outputCol=\"features\")\n\nall_assembled = assembler.transform(colors_tags)\n\n# Create k-means model, k=2, and fit the data\nkmeans = KMeans().setK(2).setSeed(1)\nkmeans_model = kmeans.fit(all_assembled)\nall_predictions = kmeans_model.transform(all_assembled)"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["# Scree plot\ncost = list()\nfor k in range(2,20):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    kmeans_model = kmeans.fit(all_assembled)\n    cost.append(kmeans_model.computeCost(all_assembled))\n\nfig, ax = plt.subplots()\nplt.plot(range(2,20), cost, 'b*-')\nplt.xticks(np.arange(1, 21, 1.0)) # this helps us see the number of clusters we want!\nplt.xlabel('Number of clusters');\nplt.ylabel('Within Set Sum of Squared Error');\nplt.title('Elbow for K-Means clustering');\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["The elbow method suggests five clusters."],"metadata":{}},{"cell_type":"code","source":["# Check Silhouette scores\ncost = list()\nevaluator = ClusteringEvaluator()\nfor k in range(2,20):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    kmeans_model = kmeans.fit(all_assembled)\n    all_predictions = kmeans_model.transform(all_assembled)\n    silhouette = evaluator.evaluate(all_predictions)\n    cost.append(silhouette)\n    \nkIdx = np.argmax(cost)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,20), cost, 'b*-')\nplt.plot(range(2,20)[kIdx], cost[kIdx], marker='o', markersize=12, \n         markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\nplt.xlim(1, plt.xlim()[1])\nplt.xticks(np.arange(1, 21, 1.0)) # this helps us see the number of clusters we want!\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Coefficient')\nplt.title('Silhouette Scores for k-means clustering')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":["The elbow method suggests 5, but the silhouette score suggests 2. Let's try 5, below:"],"metadata":{}},{"cell_type":"code","source":["# Run analysis with k = 5\nkmeans = KMeans().setK(5).setSeed(1)\nkmeans_model = kmeans.fit(all_assembled)\nall_predictions = kmeans_model.transform(all_assembled)\nbob_ross[\"prediction\"] = all_predictions.select(\"prediction\").toPandas().set_index(bob_ross.index)\n\ndf_0 = bob_ross[bob_ross[\"prediction\"] == 0]\ndisplay_images(df_0['image'],\" Cluster 1 Images\")"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["df_1 = bob_ross[bob_ross[\"prediction\"] == 1]\ndisplay_images(df_1['image'],\" Cluster 2 Images\")"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["df_2 = bob_ross[bob_ross[\"prediction\"] == 2]\ndisplay_images(df_2['image'],\" Cluster 3 Images\")"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["df_3 = bob_ross[bob_ross[\"prediction\"] == 3]\ndisplay_images(df_3['image'],\" Cluster 4 Images\")"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["df_4 = bob_ross[bob_ross[\"prediction\"] == 4]\ndisplay_images(df_4['image'],\" Cluster 5 Images\")"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":["When k = 5, and we use both tags and colors, the clusters are:\n1. Blue and white mountains, with green trees.\n2. White mountains, many with cabins.\n3. Green forests, many with a river.\n4. Oceans and waves, often with a light sunset.\n5. Trees with light green or orange leaves, and lighter sunsets."],"metadata":{}},{"cell_type":"markdown","source":["## Above and Beyond\n2. Repeat the analysis for Step 6 (both tags and colors) using bisecting k-means **and compare the results to k-means**. Describe, in detail, how the resulting clusters differ.  The majority of your work should go into exploring the differences in the results."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.clustering import BisectingKMeans\n\nbkm = BisectingKMeans().setK(3).setSeed(1)\nbkm_model = bkm.fit(all_assembled)\nall_predictions = kmeans_model.transform(all_assembled)\n"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["# Scree plot\ncost = list()\nfor k in range(2,20):\n    bkm = BisectingKMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    bkm_model = bkm.fit(all_assembled)\n    cost.append(bkm_model.computeCost(all_assembled))\n\nfig, ax = plt.subplots()\nplt.plot(range(2,20), cost, 'b*-')\nplt.xticks(np.arange(1, 21, 1.0)) # this helps us see the number of clusters we want!\nplt.xlabel('Number of clusters');\nplt.ylabel('Within Set Sum of Squared Error');\nplt.title('Elbow for Bisecting K-Means clustering');\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":["# Check Silhouette scores\ncost = list()\nevaluator = ClusteringEvaluator()\nfor k in range(2,20):\n    bkm = BisectingKMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    bkm_model = bkm.fit(all_assembled)\n    all_predictions = bkm_model.transform(all_assembled)\n    silhouette = evaluator.evaluate(all_predictions)\n    cost.append(silhouette)\n    \nkIdx = np.argmax(cost)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,20), cost, 'b*-')\nplt.plot(range(2,20)[kIdx], cost[kIdx], marker='o', markersize=12, \n         markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\nplt.xlim(1, plt.xlim()[1])\nplt.xticks(np.arange(1, 21, 1.0)) # this helps us see the number of clusters we want!\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Coefficient')\nplt.title('Silhouette Scores for Bisecting k-means clustering')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"code","source":["# Run analysis with k = 5\nbkm = BisectingKMeans().setK(5).setSeed(1)\nbkm_model = bkm.fit(all_assembled)\nall_predictions = kmeans_model.transform(all_assembled)\nbob_ross[\"prediction\"] = all_predictions.select(\"prediction\").toPandas().set_index(bob_ross.index)"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"code","source":["df_0 = bob_ross[bob_ross[\"prediction\"] == 0]\ndisplay_images(df_0['image'],\" Cluster 1 Images\")\n"],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["\ndf_1 = bob_ross[bob_ross[\"prediction\"] == 1]\ndisplay_images(df_1['image'],\" Cluster 2 Images\")\n"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":["\ndf_2 = bob_ross[bob_ross[\"prediction\"] == 2]\ndisplay_images(df_2['image'],\" Cluster 3 Images\")\n"],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["\ndf_3 = bob_ross[bob_ross[\"prediction\"] == 3]\ndisplay_images(df_3['image'],\" Cluster 4 Images\")\n\n"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["df_4 = bob_ross[bob_ross[\"prediction\"] == 4]\ndisplay_images(df_4['image'],\" Cluster 5 Images\")"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":80}],"metadata":{"name":"HW7","notebookId":1887345464685274},"nbformat":4,"nbformat_minor":0}
