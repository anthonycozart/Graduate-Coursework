{"cells":[{"cell_type":"markdown","source":["# SI 618 WN 2018 - Lab 8: Clustering\n\n## Submission Instructions:\nPlease turn in this Jupyter notebook file (both .ipynb and .html formats) on Canvas before midnight.\n\n## Objectives:\n- Be able to perform k-means clustering, bisecting k-means clustering\n- Be able to execute various techniques for picking k\n- Evaluate cluster quality\n\n## Submission Instructions:\nPlease turn in via Canvas:\n1. This Jupyter notebook file **in .html format** (not as an IPython or Jupyter notebook) \n2. The URL to the published version this notebook (you will need to publish it)"],"metadata":{}},{"cell_type":"markdown","source":["#### Load libraries"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["ACCESS_KEY = \nSECRET_KEY = \nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"si618clustering\"\nMOUNT_NAME = \"si618clustering\"\n\n# Uncomment the following line if you need to unmount the S3 bucket\n# dbutils.fs.unmount(\"/mnt/si618image/\")\n\n# mount the S3 bucket\ndbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["####Display the files in the S3 bucket"],"metadata":{}},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/mnt/%s/\" % MOUNT_NAME))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["<h2 id=\"k-means\">1. K-means</h2>\n\n<p><a href=\"http://en.wikipedia.org/wiki/K-means_clustering\">k-means</a> is one of the\nmost commonly used clustering algorithms that clusters the data points into a\npredefined number of clusters. The MLlib implementation includes a parallelized\nvariant of the <a href=\"http://en.wikipedia.org/wiki/K-means%2B%2B\">k-means++</a> method\ncalled <a href=\"http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf\">kmeans||</a>.</p>\n\n<p><code>KMeans</code> is implemented as an <code>Estimator</code> and generates a <code>KMeansModel</code> as the base model.</p>\n\n#### Estimator\n\n1. An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.\n\n2. For example, K-means, LDA, etc.\n\n\n\n<h4 id=\"input-columns\">Input Columns</h4>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th align=\"left\">Param name</th>\n      <th align=\"left\">Type(s)</th>\n      <th align=\"left\">Default</th>\n      <th align=\"left\">Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>featuresCol</td>\n      <td>Vector</td>\n      <td>\"features\"</td>\n      <td>Feature vector</td>\n    </tr>\n  </tbody>\n</table>\n\n<h4 id=\"output-columns\">Output Columns</h4>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th align=\"left\">Param name</th>\n      <th align=\"left\">Type(s)</th>\n      <th align=\"left\">Default</th>\n      <th align=\"left\">Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>predictionCol</td>\n      <td>Int</td>\n      <td>\"prediction\"</td>\n      <td>Predicted cluster center</td>\n    </tr>\n  </tbody>\n</table>"],"metadata":{}},{"cell_type":"markdown","source":["Take a quick look at the code below which applies K-means algorithm on a sample dataset. We will ask you to adapt this code to a more fun dataset.\n### Example code (just run this cell):"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\n\n# Loads data.\ndataset = spark.read.format(\"libsvm\").load(\"/mnt/si618clustering/sample_kmeans_data.txt\")\n\n# Trains a k-means model with 2 clusters. Creates a K Means object, then use .fit to model it to the data.\nkmeans = KMeans().setK(2).setSeed(1)\nmodel = kmeans.fit(dataset)\n\n# Make predictions\npredictions = model.transform(dataset)\n\n# Evaluate clustering by computing Within Set Sum of Squared Errors.\nwssse = model.computeCost(dataset)\nprint(\"Within Set Sum of Squared Errors = \" + str(wssse))\n\n# Evaluate clustering by computing Silhouette score (ranging between -1 and 1 -- 1 meaning the data point belongs to the cluster)\nevaluator = ClusteringEvaluator()\nsilhouette = evaluator.evaluate(predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n\n# Shows the result.\ncenters = model.clusterCenters()\nprint(\"Cluster Centers: \")\nfor center in centers:\n    print(center)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["## Fun Activity: Clustering of 618 Class based on Music Tastes\n\nNow let's try to create our own data and conduct K-means clustering step-by-step.\n\nEnter your music tastes in this Google Sheet (scale: 1-10): https://docs.google.com/spreadsheets/d/18wIMBbQRGR8l65s6Tmsb6IJQWZ0VlFHdH3pmiGE3WLQ/edit?usp=sharing"],"metadata":{}},{"cell_type":"markdown","source":["### After everyone enters their music preferences, Kai will upload the dataset to AWS S3.\n### Get started: Load the data we just created"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField\nfrom pyspark.sql.types import DoubleType, StringType\n\nschema = StructType([\n    StructField(\"_c0\", StringType()),\n    StructField(\"Jazz\", DoubleType()),\n    StructField(\"Soul\", DoubleType()),\n    StructField(\"Pop\", DoubleType()),\n    StructField(\"R&B\", DoubleType()),\n    StructField(\"Opera\", DoubleType()),\n    StructField(\"Country\", DoubleType()),\n    StructField(\"Rock&Roll\", DoubleType()),\n])\n\nmusic_raw = spark.read.csv(\"/mnt/si618clustering/music.tsv\", inferSchema=True, header=True, sep='\\t',schema=schema)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["music_raw.show(30)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["### Step 0 - Impute missing data"],"metadata":{}},{"cell_type":"markdown","source":["#### Spark MLLib cannot handle missing values (null values), so it's necessary to take care of them before training a model."],"metadata":{}},{"cell_type":"markdown","source":["#### Transformer\n\n1. A transformer is an abstraction which transforms a Spark DataFrame into another.\n\n2. Prepares a Spark DataFrame for a Machine Learning algorithm.\n\n3. For example, VectorAssembler, Imputer, etc."],"metadata":{}},{"cell_type":"markdown","source":["### Example code (just run this cell):"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import Imputer\n\ndf = spark.createDataFrame([\n    (1.0, float(\"nan\")),\n    (2.0, float(\"nan\")),\n    (float(\"nan\"), 3.0),\n    (4.0, 4.0),\n    (5.0, 5.0)\n], [\"a\", \"b\"])\n\n# The argument inputCols serves to tell Imputer which particular columns in our dataframe are to be imputed\n# The argument outputCols serves to tell Imputer the names of the output columns\nimputer = Imputer(inputCols=[\"a\", \"b\"], outputCols=[\"out_a\", \"out_b\"])\nmodel = imputer.fit(df)\ndf = model.transform(df)\ndf.show()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["### Model after the example to impute missing values in your music tastes features:"],"metadata":{}},{"cell_type":"code","source":["# The argument inputCols serves to tell Imputer which particular columns in our dataframe are to be imputed\n# The argument outputCols serves to tell Imputer the names of the output columns\nimputer = Imputer(inputCols=[\"Jazz\", \"Soul\", \"Pop\", \"R&B\", \"Opera\", \"Country\", \"Rock&Roll\"], \n                  outputCols=[\"Jazz\", \"Soul\", \"Pop\", \"R&B\", \"Opera\", \"Country\", \"Rock&Roll\"])\nimputer_model = imputer.fit(music_raw) \nmusic_imputed = imputer_model.transform(music_raw) \nmusic_imputed.show(5)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["###Step 1 - Assemble your features\n\nIn contrast to most ML packages out there, Spark ML requires your input features to be gathered in a single column of your dataframe, usually named features; and it provides a specific method for doing this, VectorAssembler:"],"metadata":{}},{"cell_type":"markdown","source":["####VectorAssembler\n\nVectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. \n\nVectorAssembler accepts the following input column types: all numeric types, boolean type, and vector type. In each row, the values of the input columns will be concatenated into a vector in the specified order."],"metadata":{}},{"cell_type":"markdown","source":["### Example code (just run this cell):"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\n\ndataset = spark.createDataFrame(\n    [(0, 18, 1.0, Vectors.dense([0.0, 10.0, 0.5]), 1.0)],\n    [\"id\", \"hour\", \"mobile\", \"userFeatures\", \"clicked\"])\n\n# The argument inputCols serves to tell VectoeAssembler which particular columns in our dataframe are to be used as features\nassembler = VectorAssembler(\n    inputCols=[\"hour\", \"mobile\", \"userFeatures\"],\n    outputCol=\"features\")\n\noutput = assembler.transform(dataset)\nprint(\"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\")\noutput.select(\"features\", \"clicked\").show(truncate=False)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["### Model after the example to assemble your music tastes features:"],"metadata":{}},{"cell_type":"code","source":["assembler = VectorAssembler(\n    inputCols=[\"Jazz\", \"Soul\", \"Pop\", \"R&B\", \"Opera\", \"Country\", \"Rock&Roll\"],\n    outputCol=\"features\") \n\nmusic_assembled = assembler.transform(music_imputed)\nprint(\"Assembled columns 'Jazz', 'Soul', 'Pop', 'R&B', 'Opera', 'Country', 'Rock&Roll' to vector column 'features'\")\noutput.select(\"features\").show(truncate=False)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["### For Step 2 through Step 4, copy some of the code from the cell 10, and try to adapt it to our music dataset."],"metadata":{}},{"cell_type":"markdown","source":["###Step 2 - Fit your K-means model"],"metadata":{}},{"cell_type":"code","source":["# Trains a k-means model with 3 clusters.\nkmeans = KMeans().setK(3).setSeed(1)\nkmeans_model = kmeans.fit(music_assembled) # music_assembled"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["###Step 3 - Predict using the model fit"],"metadata":{}},{"cell_type":"code","source":["# Make predictions\nmusic_predictions = kmeans_model.transform(music_assembled)\nmusic_predictions.show(5)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["###Step 4 - Evalute your K-means model"],"metadata":{}},{"cell_type":"markdown","source":["#### Evaluating Clusters\nHere is a quote from the scikit-learn's [clustering tutorial](http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation) regarding clustering performance evaluation.\n\n> Evaluating the performance of a clustering algorithm is not as trivial as counting the number of errors or the precision and recall of a supervised classification algorithm. In particular any evaluation metric should not take the absolute values of the cluster labels into account but rather if this clustering define separations of the data similar to some ground truth set of classes or satisfying some assumption such that members belong to the same class are more similar that members of different classes according to some similarity metric."],"metadata":{}},{"cell_type":"code","source":["# Evaluate clustering by computing Within Set Sum of Squared Errors.\nwssse = kmeans_model.computeCost(music_assembled)\nprint(\"Within Set Sum of Squared Errors = \" + str(wssse))"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["# Evaluate clustering by computing Silhouette score\nevaluator = ClusteringEvaluator()\nsilhouette = evaluator.evaluate(music_predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["###Step 4 - Show the cluster centers and cluster assignments"],"metadata":{}},{"cell_type":"code","source":["# Shows the clustering centers\ncenters = kmeans_model.clusterCenters()\nprint(\"Cluster Centers: \")\nfor center in centers:\n    print(center)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# Shows the clustering membership\nmusic_transformed = kmeans_model.transform(music_assembled)\nmusic_transformed.show(5)  "],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["### Do you and your friends have similar music tastes? Do you belong to the same cluster? :)\n\nYES. I'm so relieved. :)"],"metadata":{}},{"cell_type":"markdown","source":["### Step 5 - Visualize the results"],"metadata":{}},{"cell_type":"markdown","source":["#### Choose 3 dimensions(\"Jazz\", \"Soul\", Pop\") to visualize the clusters in a 3D plot"],"metadata":{}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import axes3d, Axes3D\n\npddf_pred = music_transformed.select(\"_c0\",\"Pop\",\"Country\",\"Rock&Roll\",\"prediction\").toPandas().set_index('_c0')\npddf_pred.head()\n\nthreedee = plt.figure(figsize=(6,4)).gca(projection='3d')\nthreedee.scatter(pddf_pred.Pop, pddf_pred.Country, pddf_pred['Rock&Roll'], c=pddf_pred.prediction)\nthreedee.set_xlabel('Pop')\nthreedee.set_ylabel('Country')\nthreedee.set_zlabel('Rock&Roll')\ndisplay(threedee.figure)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["#### Display a pairplot of the first three features, segmented by clusters."],"metadata":{}},{"cell_type":"code","source":["display(kmeans_model, music_transformed.select(\"features\"))"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":["##2. Bisecting k-means\n\nBisecting k-means is a kind of hierarchical clustering using a divisive (or “top-down”) approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.\n\nBisecting K-means can often be much faster than regular K-means, but it will generally produce a different clustering."],"metadata":{}},{"cell_type":"markdown","source":["### Example code (just run this cell):"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.clustering import BisectingKMeans\n\n# Trains a bisecting k-means model.\nbkm = BisectingKMeans().setK(2).setSeed(1)\nmodel = bkm.fit(output)\n\n# Evaluate clustering by computing Within Set Sum of Squared Errors.\ncost = model.computeCost(output)\nprint(\"Within Set Sum of Squared Errors = \" + str(cost))\n\n# Evaluate clustering by computing Silhouette score\nevaluator = ClusteringEvaluator()\nsilhouette = evaluator.evaluate(predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n\n# Shows the result.\nprint(\"Cluster Centers: \")\ncenters = model.clusterCenters()\nfor center in centers:\n    print(center)\n"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["### Model after the example to conduct a Bisecting K-means algorithm on the music tastes dataset with 3 clusters. Repeat Step 2 - Step 4 just like in the K-means clustering."],"metadata":{}},{"cell_type":"code","source":["# Trains a bisecting k-means model.\n\nbkm = BisectingKMeans().setK(3).setSeed(1)\nbkm_model = bkm.fit(music_assembled)\n\nmusic_predictions = bkm_model.transform(music_assembled)\n\n# Evaluate clustering by computing Within Set Sum of Squared Errors.\nwssse = bkm_model.computeCost(music_assembled)\n\n# Evaluate clustering by computing Silhouette score\nevaluator = ClusteringEvaluator()\nsilhouette = evaluator.evaluate(music_predictions)\nprint(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n\n# Shows the result.\nprint(\"Cluster Centers: \")\ncenters = bkm_model.clusterCenters()\nfor center in centers:\n    print(center)\n\n# Shows the clustering membership\nmusic_transformed_bkm = bkm_model.transform(music_assembled)\nmusic_transformed_bkm.show(5)  "],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["## 3. Picking K - How many clusters?\n\nA number of clustering methods, such as k-means, assumes the parameter _k_ (#clusters) is known in advance, which is often not the case in practice. A number of techniques exist for determining the number of clusters in a dataset. See [this Wikipedia page](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set#Information_Criterion_Approach) for a detailed discussion.\n\nIn this section, we focus on four of the approaches:\n0. Use your eyeballs\n1. Rule of thumb\n2. The Elbow Method\n3. The Silhouette Approach\n\nLet us see if all the methods listed above will be able to recover the true number of clusters."],"metadata":{}},{"cell_type":"markdown","source":["## 3.1 Rule of thumb:\nChoosing the number of clusters to simply be\n\n$$\nk \\approx \\sqrt{n/2}\n$$\n\nwhere n is the number of observations."],"metadata":{}},{"cell_type":"code","source":["np.sqrt(music_assembled.count()/2)"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":["## 3.2 The Elbow Method (Scree Plot)\nPlot the percentage of variance explained as a function of the number of clusters.\n\nYou can reduce this error measure by increasing k. In fact the optimal k is usually one where there is an “elbow” in the elbow graph.\n\nSee [here](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set#The_Elbow_Method) for an explanation."],"metadata":{}},{"cell_type":"code","source":["cost = list()\nfor k in range(2,11):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    kmeans_model = kmeans.fit(music_assembled)\n    cost.append(kmeans_model.computeCost(music_assembled)/k)\n\nprint(cost)"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":["#### Plot the Within Set Sum of Squared Errors as a function of number of clusters"],"metadata":{}},{"cell_type":"code","source":["fig, ax = plt.subplots()\nplt.plot(range(2,11), cost, 'b*-')\nplt.xlabel('Number of clusters');\nplt.ylabel('Within Set Sum of Squared Error');\nplt.title('Elbow for K-Means clustering');\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":["## 3.3 The Silhouette Approach\nThe silhouette coefficient can be used for evaluating clustering where there lacks ground truth. We can use the same metric for the purpose of finding the best k for the dataset."],"metadata":{}},{"cell_type":"code","source":["cost = list()\nevaluator = ClusteringEvaluator()\nfor k in range(2,11):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    kmeans_model = kmeans.fit(music_assembled)\n    music_predictions = kmeans_model.transform(music_assembled)\n    silhouette = evaluator.evaluate(music_predictions)\n    cost.append(silhouette)"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":["#### Plot the silhouette scores as a function of number of clusters"],"metadata":{}},{"cell_type":"code","source":["kIdx = np.argmax(cost)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,11), cost, 'b*-')\nplt.plot(range(2,11)[kIdx], cost[kIdx], marker='o', markersize=12, \n         markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\nplt.xlim(1, plt.xlim()[1])\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Coefficient')\nplt.title('Silhouette Scores for k-means clustering')\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["### Model after one of the above method to pick the best K for Bisecting K-means algorithm on our music dataset. What is the best K according to your analysis?"],"metadata":{}},{"cell_type":"code","source":["np.sqrt(music_assembled.count()/2)"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":["We ran out of time!"],"metadata":{}},{"cell_type":"markdown","source":["# End of Lab 8"],"metadata":{}}],"metadata":{"name":"Lab8_JACozart","notebookId":3056138696430113},"nbformat":4,"nbformat_minor":0}
